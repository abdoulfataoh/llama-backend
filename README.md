## llama-backend

Llama-backend is a scalable and reliable backend service that provides a robust API for managing requests to the llama model. It is designed to be easy to use and integrate with existing applications, and it is built on top of modern technologies such as FastAPI and Celery.

### Requierments

We use [poetry](https://python-poetry.org/) in this project to manage virtual env and dependancies. To install poetry, run the follwing command

```bash
curl -sSL https://install.python-poetry.org | python3 -
```

### Installation